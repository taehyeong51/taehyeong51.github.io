{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q_bSPrm91LS4"
   },
   "source": [
    "딥러닝의 이해 10주차 2차시 수업 과정인 CNN으로 MNIST 분류하기 진행해보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "co2G8nt9hCsp"
   },
   "source": [
    "**Import**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "67v_jPnFglUe",
    "outputId": "676c6ea2-55c7-4be3-8b13-03fe06f889d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "다음 기기로 학습합니다. : cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# torch.cuda.is_availbe() 를 통해 GPU가 사용가능한 status인지 아닌지를 bool형태(True or False)로 리턴\n",
    "USE_CUDA = torch.cuda.is_available() \n",
    "\n",
    "# 만약 USE_CUDA = True (GPU 사용가능)이면 device = \"cuda\", USE_CUDA = False (GPU 사용 불가능하면 CPU 사용)이면 device = \"CPU\"\n",
    "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\") \n",
    "\n",
    "# 사용 device 출력\n",
    "print(\"다음 기기로 학습합니다. :\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EArEKqYNhH38"
   },
   "source": [
    "**초기설정 : Batch, Epoch,Seed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sLd1qAyig_PZ"
   },
   "outputs": [],
   "source": [
    "#for reproducibility (재현성을 위해 동일한 방식으로 Shuffle 하기 위한 Random 값 고정)\n",
    "random.seed(777)\n",
    "torch.manual_seed(777)\n",
    "if device == 'cuda':\n",
    "  torch.cuda.manual_seed_all(777)\n",
    "\n",
    "# hyperparameters\n",
    "\n",
    "# Epcoh 횟수 = 15\n",
    "training_epochs = 15 \n",
    "# Batch 크기 = 100\n",
    "batch_size = 100 \n",
    "# learning rate = 0.001\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sWmE39jMjGAz"
   },
   "source": [
    "**MNIST Dataset**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gAnKKgSC6awr"
   },
   "source": [
    "``` python\n",
    "torchvision.datasets.MNIST(root: str, train: bool = True, transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, download: bool = False)\n",
    "```\n",
    "\n",
    "- **`root`**(string) : `MNIST/raw/train-images-idx3-ubyte`와 `MNIST/raw/t10k-images-idx3-ubyte` 가 저장될 경로를 지정합니다.\n",
    "\n",
    "- **`train`**(*bool*,optional) : data를 통해 train할 때 `True`로 설정합니다. 만약 `True` 로 설정되면 `train-images-idx3-ubyte`로부터 dataset을 형성합니다. `False`이면 `t10k-images-idx3-ubyte`로부터 dataset을 형성합니다. \n",
    "\n",
    "- **`download`**(*bool*,optional) : True이면 인터넷을 통해 dataset을 download하고 설정한 root directory에 저장합니다. 만약 이미 download된 파일이 있다면 다시 download하지 않습니다. \n",
    "\n",
    "- **`transform`**(*callable*, optional) : PIL 이미지를 입력받아 transformed 된 결과를 return하는 함수입니다. <br>E.g, `transforms.RandomCrop`\n",
    "\n",
    "이외 parameter에 대한 상세한 설명은 [pytorch - MNIST](https://pytorch.org/vision/stable/generated/torchvision.datasets.MNIST.html#torchvision.datasets.MNIST) 를 참조하시기 바랍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p5ynsJIRjJK-"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "torchvision에서 dsets로 import 한 datasets 통해 \n",
    "built-in datasets 중 하나인 MNIST dataset download\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "mnist_train = dsets.MNIST(root='MNIST_data/', # download 받을 경로 지정\n",
    "                          train = True, # train을 위한 data이므로 True로 설정\n",
    "                          transform = transforms.ToTensor(), # Data를 Tensor로 변환\n",
    "                          download = True)\n",
    "\n",
    "mnist_test = dsets.MNIST(root='MNIST_data/',\n",
    "                         train = False, # test를 위한 data이므로 False로 설정\n",
    "                         transform = transforms.ToTensor(), # Data를 Tensor로 변환\n",
    "                         download = True)\n",
    "\n",
    "#dataset loader\n",
    "data_loader = DataLoader(dataset = mnist_train,\n",
    "                         batch_size = batch_size, # 앞서 설정한 batch_size를 통해 batch로 나눔\n",
    "                         shuffle = True, # shuffle = True로 설정해 데이터를 무작위로 섞음, 이때 앞서 설정한 random.seed(777)을 통해 randomnize됨\n",
    "                         drop_last = True) # batch단위로 데이터를 불러올 때, 나누어 떨어지지않는다면 남은 데이터는 버림\n",
    "                                           # ex. data크기 = 27, batch_size = 5 => 마지막 batch의 크기는 2이므로 버림\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7f6xJxlKkCAi"
   },
   "source": [
    "**Network, loss, and Optimizer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gC0TjojRInZ8"
   },
   "source": [
    "class를 설정하기 위한 함수들\n",
    "\n",
    "`conv2d` - [Pytorch Conv2d 함수 다루기](https://gaussian37.github.io/dl-pytorch-conv2d/)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sfXFsgkKkE16"
   },
   "outputs": [],
   "source": [
    "# MNIST data image of shape 28 x 28 = 784\n",
    "\n",
    "# Non-linear Architecture including hidden layer\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.conv1 = nn.Conv2d(in_channels = 1,out_channels=32,kernel_size = 3,stride = 1,padding = 1)\n",
    "    self.conv2 = nn.Conv2d(32,64,3,1,1)\n",
    "    self.pool = nn.MaxPool2d(kernel_size = 2,stride = 2)\n",
    "    self.fc = nn.Linear(64*7*7,10,bias = True)\n",
    "    torch.nn.init.xavier_uniform_(self.fc.weight)\n",
    "  def forward(self,x):\n",
    "    # L1 Imgin shape = (batch_size,1,28,28)\n",
    "    # \"self.conv1(x)\" => (batch_size,32,28,28)\n",
    "    # \"self.pool(x)\" => (batch_size,32,14,14), Conv2d에서 padding = 1 설정함으로써 MaxPooling 통해 가장 자리 삭제되는 것 방지\n",
    "    x = self.pool(F.relu(self.conv1(x)))\n",
    "\n",
    "    # L2 Imgin shappe = (batch_size,32,14,14)\n",
    "    # \"self.conv1(x)\" => (batch_size,64,14,14)\n",
    "    # \"self.pool(x)\" => (batch_size,64,7,7)\n",
    "    x = self.pool(F.relu(self.conv2(x)))\n",
    "\n",
    "    # L3 FC 64x7x7(3136) inputs -> 10 outputs\n",
    "    # \"torch.flatten(x,1)\"\" => (batch_size,1024)\n",
    "    x = torch.flatten(x,1) # 0,1,2 차원으로 flatten.. 1차원 => width*height\n",
    "    x = self.fc(x)\n",
    "    return x\n",
    "\n",
    "net = Net().to(device)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss().to(device) # 내부적으로 Softmax 함수 포함하고 있음\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YC64-PT-kUWf"
   },
   "source": [
    "**Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zy6juX-Npieb",
    "outputId": "d6feab1e-b8da-4f22-d4e5-38cb7f908efb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001, cost = 0.225624949\n",
      "Epoch: 0002, cost = 0.062987588\n",
      "Epoch: 0003, cost = 0.046228435\n",
      "Epoch: 0004, cost = 0.037454057\n",
      "Epoch: 0005, cost = 0.031482313\n",
      "Epoch: 0006, cost = 0.026145909\n",
      "Epoch: 0007, cost = 0.021883152\n",
      "Epoch: 0008, cost = 0.018382354\n",
      "Epoch: 0009, cost = 0.016457239\n",
      "Epoch: 0010, cost = 0.013288155\n",
      "Epoch: 0011, cost = 0.010470187\n",
      "Epoch: 0012, cost = 0.010075552\n",
      "Epoch: 0013, cost = 0.008410202\n",
      "Epoch: 0014, cost = 0.007457465\n",
      "Epoch: 0015, cost = 0.006478167\n",
      "Learning Finished\n"
     ]
    }
   ],
   "source": [
    "total_batch = len(data_loader)\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "  avg_cost = 0\n",
    "  for X,Y in data_loader:\n",
    "    # 배치 크기 = 100\n",
    "    X = X.to(device) # Batch, Channel, Width, Height\n",
    "    Y = Y.to(device)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Hypothesis for Non-linear Architecture\n",
    "    hypothesis = net(X)\n",
    "\n",
    "    # cost, optimizer\n",
    "    cost = criterion(hypothesis,Y)\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    avg_cost += cost / total_batch\n",
    "  \n",
    "  print(f\"Epoch: {epoch+1:04d}, cost = {avg_cost:.9f}\")\n",
    "\n",
    "print(\"Learning Finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "blLmzK6cmXZN"
   },
   "source": [
    "**Test Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "id": "IsJ6ot7jnSy2",
    "outputId": "3305b6a1-1790-4d06-c54c-69cca2554f4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9830999970436096\n",
      "Label: 8\n",
      "Prediction : 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:80: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n",
      "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:70: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "  X_test = mnist_test.test_data.reshape(-1,1,28,28).float().to(device)  # Test Data도 Batch, Channel, Width, Height로 reshpae\n",
    "  Y_test = mnist_test.test_labels.to(device)\n",
    "  prediction = net(X_test)\n",
    "  correct_prediction = torch.argmax(prediction,1) == Y_test\n",
    "  accuracy = correct_prediction.float().mean()\n",
    "  print(\"Accuracy:\", accuracy.item())\n",
    "\n",
    "  # MNIST 테스트 데이터에서 무작위로 하나 뽑아서 예측\n",
    "  r = random.randint(0,len(mnist_test) - 1)\n",
    "  X_single_data = mnist_test.test_data[r:r+1].reshape(-1,1,28,28).float().to(device) # Test Data도 Batch, Channel, Width, Height로 reshpae\n",
    "  Y_single_data = mnist_test.test_labels[r:r+1].to(device)\n",
    "\n",
    "  print(\"Label:\",Y_single_data.item())\n",
    "  single_prediction = net(X_single_data)\n",
    "  print(\"Prediction :\", torch.argmax(single_prediction,1).item())\n",
    "\n",
    "  plt.imshow(mnist_test.test_data[r:r+1].view(28,28), cmap='Greys', interpolation = 'nearest')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qID_Tzu8t_jG"
   },
   "source": [
    "**Reference**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "br7qW8-UuCOr"
   },
   "source": [
    "1. Conv2d 함수 : https://gaussian37.github.io/dl-pytorch-conv2d/\n",
    "\n",
    "2. Channel Size Fix : https://discuss.pytorch.org/t/runtimeerror-expected-3d-unbatched-or-4d-batched-input-to-conv2d-but-got-input-of-size-1-1-374-402-3/154535\n",
    "\n",
    "3. nn.functional : https://thebook.io/080289/ch05/02-16/\n",
    "\n",
    "4. Pytorch로 시작하는 딥러닝 입문 : https://wikidocs.net/63565"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
